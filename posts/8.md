The reason the Internet works is because it's interconnected. More than just hyperlinks pointing to things, websites can *talk* to each other and present context-specific information that they themselves don't necessarily contain, e.g. which of your friends like a website via. the Facebook "Like" button. Best of all, everything is distributed.

Why, then, do applications on our computers behave like silos?

Why doesn't my feed reader know my browser history (so that it can tell me if I've already read an article)? Why doesn't my browser know that I've already downloaded the file I'm trying to download now? Why doesn't my text editor know which email the document I'm currently editing was attached to?

The obvious way to solve this problem would be to do what we do on the web: allow individual applications to expose APIs that other applications can call to get more information. The not so obvious are things like avoiding duplication (something even the web struggles with, which if you've ever joined more than one social network, you've faced). But we could start small, like apps being able to query application specific information about things â€” like Reeder being able to ask Chrome if I've already visited the link pointed to by the article I'm reading.

I don't know, this seems like a problem we would have at least tried to solve, but I don't think OS' even support anything that might allow this. The most interoperability I've seen is registering application specific protocols so that when I open a `itunes://` link in Chrome, it opens in iTunes. I suppose it was cool in 2008, but four years later that's still all we have.